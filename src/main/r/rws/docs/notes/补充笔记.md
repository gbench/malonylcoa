# R语言补充内容

## 一、统计建模与机器学习

### 1.1 线性回归与广义线性模型

```r
# 线性回归
lm_model <- lm(mpg ~ wt + cyl, data = mtcars)
summary(lm_model)
coef(lm_model)
confint(lm_model)

# 模型诊断
par(mfrow = c(2, 2))
plot(lm_model)

# 预测
new_data <- data.frame(wt = c(2.5, 3.0), cyl = c(4, 6))
predict(lm_model, newdata = new_data, interval = "confidence")

# 广义线性模型（逻辑回归）
glm_model <- glm(am ~ wt + hp, data = mtcars, family = binomial)
summary(glm_model)

# 多项逻辑回归
library(nnet)
multinom_model <- multinom(Species ~ Sepal.Length + Sepal.Width, data = iris)
summary(multinom_model)
```

### 1.2 混合效应模型

```r
# 线性混合效应模型
library(lme4)
library(lmerTest)

# 随机截距模型
lmer_model <- lmer(Reaction ~ Days + (1|Subject), data = sleepstudy)
summary(lmer_model)

# 随机斜率和截距模型
lmer_model2 <- lmer(Reaction ~ Days + (Days|Subject), data = sleepstudy)
summary(lmer_model2)

# 模型比较
anova(lmer_model, lmer_model2)

# 预测
predict(lmer_model, newdata = data.frame(Days = 5, Subject = "308"))
```

### 1.3 时间序列分析

```r
# 时间序列对象
ts_data <- ts(AirPassengers, frequency = 12, start = c(1949, 1))

# 分解时间序列
decomposed <- decompose(ts_data)
plot(decomposed)

# 自相关和偏自相关
acf(ts_data)
pacf(ts_data)

# ARIMA模型
arima_model <- arima(ts_data, order = c(1, 1, 1), seasonal = c(1, 1, 1))
summary(arima_model)
forecast_values <- predict(arima_model, n.ahead = 12)

# 状态空间模型
library(KFAS)
ssm_model <- SSModel(log(ts_data) ~ SSMtrend(1, Q = list(NA)) + 
                     SSMseasonal(12, sea.type = 'dummy'), H = NA)
fit <- fitSSM(ssm_model, inits = c(0, 0))
```

### 1.4 机器学习算法

```r
# 使用caret包进行机器学习
library(caret)
library(randomForest)

# 数据预处理
preProc <- preProcess(iris[, 1:4], method = c("center", "scale"))
iris_scaled <- predict(preProc, iris[, 1:4])

# 训练测试分割
set.seed(123)
trainIndex <- createDataPartition(iris$Species, p = 0.8, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]

# 随机森林
rf_model <- randomForest(Species ~ ., data = trainData, ntree = 500)
rf_pred <- predict(rf_model, testData)
confusionMatrix(rf_pred, testData$Species)

# 支持向量机
library(e1071)
svm_model <- svm(Species ~ ., data = trainData, kernel = "radial", 
                 cost = 10, gamma = 0.1)
svm_pred <- predict(svm_model, testData)
confusionMatrix(svm_pred, testData$Species)

# XGBoost
library(xgboost)
# 转换数据格式
dtrain <- xgb.DMatrix(data = as.matrix(trainData[, 1:4]), 
                      label = as.numeric(trainData$Species) - 1)
dtest <- xgb.DMatrix(data = as.matrix(testData[, 1:4]), 
                     label = as.numeric(testData$Species) - 1)

# 训练模型
xgb_model <- xgboost(data = dtrain, nrounds = 100, 
                     objective = "multi:softprob", num_class = 3,
                     eval_metric = "mlogloss")

# 预测
xgb_pred <- predict(xgb_model, dtest)
xgb_pred_matrix <- matrix(xgb_pred, ncol = 3, byrow = TRUE)
xgb_pred_class <- apply(xgb_pred_matrix, 1, which.max) - 1
confusionMatrix(factor(xgb_pred_class, levels = 0:2), 
                factor(as.numeric(testData$Species) - 1, levels = 0:2))
```

### 1.5 聚类分析

```r
# K-means聚类
set.seed(123)
kmeans_result <- kmeans(iris[, 1:4], centers = 3, nstart = 25)
table(kmeans_result$cluster, iris$Species)

# 可视化聚类结果
library(factoextra)
fviz_cluster(kmeans_result, data = iris[, 1:4], 
             palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
             geom = "point", ellipse.type = "convex")

# 层次聚类
dist_matrix <- dist(iris[, 1:4])
hc_result <- hclust(dist_matrix, method = "ward.D2")
plot(hc_result)
rect.hclust(hc_result, k = 3, border = 2:4)

# DBSCAN聚类
library(dbscan)
dbscan_result <- dbscan(iris[, 1:4], eps = 0.5, minPts = 5)
fviz_cluster(dbscan_result, data = iris[, 1:4], 
             stand = FALSE, ellipse = FALSE, show.clust.cent = FALSE)
```

## 二、数据输入输出

### 2.1 多种数据格式处理

```r
# JSON数据
library(jsonlite)
json_data <- fromJSON('{"name": "John", "age": 30, "city": "New York"}')
toJSON(json_data, pretty = TRUE)

# XML数据
library(xml2)
xml_data <- read_xml('<root><person><name>John</name><age>30</age></person></root>')
xml_text(xml_find_first(xml_data, "//name"))

# YAML数据
library(yaml)
yaml_data <- yaml.load("name: John\nage: 30\ncity: New York")
yaml_data$name

# Feather格式（高效二进制存储）
library(feather)
write_feather(iris, "iris.feather")
iris_read <- read_feather("iris.feather")

# Parquet格式
library(arrow)
write_parquet(iris, "iris.parquet")
iris_parquet <- read_parquet("iris.parquet")

# HDF5格式
library(rhdf5)
h5createFile("example.h5")
h5write(iris, "example.h5", "iris")
h5read("example.h5", "iris")
```

### 2.2 数据库连接

```r
# SQLite
library(RSQLite)
con <- dbConnect(SQLite(), "mydatabase.db")
dbWriteTable(con, "mtcars", mtcars)
result <- dbGetQuery(con, "SELECT * FROM mtcars WHERE mpg > 20")
dbDisconnect(con)

# PostgreSQL
library(RPostgreSQL)
con <- dbConnect(PostgreSQL(), 
                 dbname = "mydb", 
                 host = "localhost",
                 port = 5432,
                 user = "user",
                 password = "password")
dbGetQuery(con, "SELECT * FROM mytable")
dbDisconnect(con)

# MySQL
library(RMySQL)
con <- dbConnect(MySQL(),
                 dbname = "mydb",
                 host = "localhost",
                 port = 3306,
                 user = "user",
                 password = "password")
dbGetQuery(con, "SELECT * FROM mytable")
dbDisconnect(con)

# 使用DBI统一接口
library(DBI)
con <- dbConnect(RSQLite::SQLite(), "mydatabase.db")
dbListTables(con)
dbGetQuery(con, "SELECT * FROM mtcars LIMIT 5")
dbDisconnect(con)
```

### 2.3 Web数据抓取

```r
# 使用rvest进行网页抓取
library(rvest)
library(httr)

# 简单的网页抓取
url <- "https://en.wikipedia.org/wiki/List_of_countries_by_population_(United_Nations)"
page <- read_html(url)
tables <- html_table(page, fill = TRUE)
population_table <- tables[[1]]

# 处理JavaScript渲染的页面
library(RSelenium)
remDr <- remoteDriver(remoteServerAddr = "localhost", 
                      port = 4444L, 
                      browserName = "chrome")
remDr$open()
remDr$navigate("https://example.com")
page_source <- remDr$getPageSource()[[1]]
remDr$close()

# API请求
library(httr)
response <- GET("https://api.github.com/users/hadley/repos")
content <- content(response, "parsed")
repos <- do.call(rbind, lapply(content, as.data.frame))

# 使用API包装包
library(rtweet)
tweets <- search_tweets("#rstats", n = 100)
users <- search_users("#rstats", n = 100)
```

## 三、高级可视化

### 3.1 基础绘图系统

```r
# 基础绘图系统概览
# 散点图
plot(mtcars$wt, mtcars$mpg, 
     main = "汽车重量与油耗关系",
     xlab = "重量(吨)", ylab = "油耗(英里/加仑)",
     pch = 19, col = factor(mtcars$cyl))

# 添加回归线
abline(lm(mpg ~ wt, data = mtcars), col = "red", lwd = 2)

# 直方图
hist(mtcars$mpg, breaks = 15, 
     main = "油耗分布",
     xlab = "油耗(英里/加仑)", 
     col = "lightblue",
     border = "black")

# 箱线图
boxplot(mpg ~ cyl, data = mtcars,
        main = "不同气缸数的油耗比较",
        xlab = "气缸数", ylab = "油耗(英里/加仑)",
        col = rainbow(3))

# 多图布局
par(mfrow = c(2, 2))
plot(mtcars$wt, mtcars$mpg, main = "散点图")
hist(mtcars$mpg, main = "直方图")
boxplot(mtcars$mpg, main = "箱线图")
pie(table(mtcars$cyl), main = "饼图")
```

### 3.2 lattice绘图系统

```r
library(lattice)

# 条件散点图
xyplot(mpg ~ wt | factor(cyl), data = mtcars,
       main = "按气缸数分组的散点图",
       xlab = "重量", ylab = "油耗",
       layout = c(3, 1))

# 水平箱线图
bwplot(~ mpg | factor(cyl), data = mtcars,
       main = "按气缸数分组的箱线图",
       xlab = "油耗")

# 密度图
densityplot(~ mpg, groups = cyl, data = mtcars,
            main = "不同气缸数的油耗密度",
            xlab = "油耗",
            auto.key = list(columns = 3))

# 3D散点图
cloud(mpg ~ wt * hp, data = mtcars,
      main = "3D散点图",
      zlab = "油耗", xlab = "重量", ylab = "马力",
      screen = list(z = 30, x = -60))
```

### 3.3 交互式可视化

```r
# plotly交互式图表
library(plotly)

# 交互式散点图
p <- plot_ly(mtcars, x = ~wt, y = ~mpg, 
             type = "scatter", mode = "markers",
             color = ~factor(cyl), 
             text = ~paste("车型:", rownames(mtcars)),
             hoverinfo = "text")
p

# 交互式3D图
plot_ly(mtcars, x = ~wt, y = ~hp, z = ~mpg,
        color = ~factor(cyl), 
        type = "scatter3d", mode = "markers")

# 交互式热图
heatmaply(cor(mtcars), 
          main = "mtcars数据集相关性热图",
          k_col = 2, k_row = 2)

# dygraphs时间序列
library(dygraphs)
dygraph(AirPassengers, main = "航空旅客数量") %>%
  dyRangeSelector()

# leaflet地图
library(leaflet)
leaflet() %>%
  addTiles() %>%
  addMarkers(lng = -74.0060, lat = 40.7128, 
             popup = "纽约市")
```

### 3.4 高级ggplot2技巧

```r
library(ggplot2)
library(gganimate)
library(ggrepel)

# 复杂图形组合
p1 <- ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "油耗与重量关系", 
       x = "重量(吨)", y = "油耗(英里/加仑)") +
  theme_minimal()

# 分面图
p2 <- ggplot(mtcars, aes(x = wt, y = mpg)) +
  geom_point() +
  facet_wrap(~ cyl, nrow = 1) +
  stat_smooth(method = "lm") +
  labs(title = "按气缸数分组")

# 动画
animated_plot <- ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +
  geom_point(size = 3) +
  transition_states(cyl, transition_length = 2, state_length = 1) +
  labs(title = "气缸数: {closest_state}")

# 保存动画
animate(animated_plot, renderer = gifski_renderer("animated.gif"))

# 使用ggrepel避免标签重叠
ggplot(mtcars, aes(x = wt, y = mpg, label = rownames(mtcars))) +
  geom_point() +
  geom_text_repel(max.overlaps = 10) +
  theme_minimal()
```

## 四、并行计算与高性能计算

### 4.1 基础并行计算

```r
# 使用parallel包
library(parallel)

# 检测核心数
num_cores <- detectCores()
cat("可用核心数:", num_cores)

# 使用mclapply（仅限Unix-like系统）
results <- mclapply(1:100, function(i) {
  Sys.sleep(0.1)  # 模拟耗时操作
  i^2
}, mc.cores = num_cores)

# 使用parLapply（跨平台）
cl <- makeCluster(num_cores)
clusterExport(cl, "some_function")
results <- parLapply(cl, 1:100, function(i) {
  some_function(i)
})
stopCluster(cl)

# 使用foreach包
library(foreach)
library(doParallel)

# 注册并行后端
registerDoParallel(cores = num_cores)

# 并行循环
results <- foreach(i = 1:100, .combine = c) %dopar% {
  sqrt(i)
}

# 使用.combine参数合并结果
matrix_result <- foreach(i = 1:10, .combine = rbind) %dopar% {
  c(i, i^2, i^3)
}

# 停止并行后端
stopImplicitCluster()
```

### 4.2 大数据处理

```r
# 使用data.table处理大数据
library(data.table)

# 创建大数据集
set.seed(123)
big_data <- data.table(
  id = 1:1e7,
  group = sample(LETTERS[1:10], 1e7, replace = TRUE),
  value1 = rnorm(1e7),
  value2 = runif(1e7)
)

# 高效查询
system.time({
  result <- big_data[group == "A", .(mean_value = mean(value1)), by = .(group)]
})

# 内存映射文件
library(bigmemory)
big_matrix <- big.matrix(nrow = 10000, ncol = 1000, 
                         init = 0, 
                         backingfile = "big_matrix.bin",
                         descriptorfile = "big_matrix.desc")

# 使用ff包处理磁盘上的大数据
library(ff)
ff_matrix <- ff(0, dim = c(10000, 1000))
ff_matrix[1:1000, 1:100] <- rnorm(100000)

# 使用disk.frame处理超大数据
library(disk.frame)
df <- as.disk.frame(big_data, outdir = "temp_df", nchunks = 10)
result <- df %>%
  srckeep(c("group", "value1")) %>%
  group_by(group) %>%
  summarise(mean_value = mean(value1)) %>%
  collect()
```

### 4.3 Rcpp：C++集成

```r
# Rcpp示例
library(Rcpp)

# 直接在R中编写C++代码
cppFunction('
double sumC(NumericVector x) {
  int n = x.size();
  double total = 0;
  for(int i = 0; i < n; ++i) {
    total += x[i];
  }
  return total;
}')

# 测试性能
x <- rnorm(1e7)
system.time(sum(x))
system.time(sumC(x))

# 使用RcppArmadillo进行矩阵运算
cppFunction(depends = "RcppArmadillo", '
arma::mat matrixPower(arma::mat X, int power) {
  return arma::pow(X, power);
}')

# 使用RcppParallel进行并行计算
library(RcppParallel)
cppFunction(depends = "RcppParallel", '
Rcpp::NumericVector parallelSum(Rcpp::NumericVector x) {
  // 并行求和实现
  return x;
}')
```

## 五、调试与性能分析

### 5.1 调试工具

```r
# 基本调试函数
debug(lm)  # 进入调试模式
lm(mpg ~ wt, data = mtcars)
undebug(lm)  # 退出调试模式

# 条件调试
debugonce(mean)  # 仅调试一次

# 浏览器调试
my_function <- function(x) {
  browser()  # 在此处暂停
  result <- x * 2
  return(result)
}

# 追踪函数调用
trace("mean", browser, exit = browser)

# 使用recover进行错误调试
options(error = recover)
# 当错误发生时，可以选择进入哪个调用层次

# 使用debugger
dump.frames(to.file = TRUE)  # 保存错误上下文
load("last.dump.rda")
debugger(last.dump)  # 交互式调试
```

### 5.2 性能分析

```r
# 使用Rprof进行性能分析
Rprof("profile.out")
# 执行需要分析的代码
for (i in 1:10000) {
  sum(rnorm(1000))
}
Rprof(NULL)

# 查看分析结果
summaryRprof("profile.out")

# 使用profvis进行可视化性能分析
library(profvis)

profvis({
  data <- matrix(rnorm(1000000), ncol = 1000)
  result <- apply(data, 2, mean)
  result2 <- colMeans(data)
})

# 基准测试
library(microbenchmark)

microbenchmark(
  apply_method = apply(mtcars, 2, mean),
  colMeans_method = colMeans(mtcars),
  lapply_method = lapply(mtcars, mean),
  times = 1000
)

# 内存分析
library(pryr)
object_size(mtcars)  # 对象大小
mem_used()  # 当前内存使用量
mem_change(x <- rnorm(1e6))  # 内存变化

# 使用bench包进行更全面的基准测试
library(bench)
bench::mark(
  apply_method = apply(mtcars, 2, mean),
  colMeans_method = colMeans(mtcars),
  check = FALSE
)
```

### 5.3 代码优化技巧

```r
# 向量化操作 vs 循环
# 慢：循环
slow_sum <- function(x) {
  total <- 0
  for (i in 1:length(x)) {
    total <- total + x[i]
  }
  total
}

# 快：向量化
fast_sum <- function(x) {
  sum(x)
}

# 预分配内存
# 慢：动态增长
slow_grow <- function(n) {
  result <- NULL
  for (i in 1:n) {
    result <- c(result, i^2)
  }
  result
}

# 快：预分配
fast_grow <- function(n) {
  result <- numeric(n)
  for (i in 1:n) {
    result[i] <- i^2
  }
  result
}

# 使用适当的数据结构
# 慢：频繁修改数据框
slow_df <- function(n) {
  df <- data.frame()
  for (i in 1:n) {
    df <- rbind(df, data.frame(x = i, y = i^2))
  }
  df
}

# 快：使用列表后合并
fast_df <- function(n) {
  rows <- vector("list", n)
  for (i in 1:n) {
    rows[[i]] <- data.frame(x = i, y = i^2)
  }
  do.call(rbind, rows)
}

# 使用内置函数
# 慢：自定义实现
slow_mean <- function(x) {
  sum(x) / length(x)
}

# 快：内置函数
fast_mean <- function(x) {
  mean(x)
}
```

## 六、报告生成与交互式应用

### 6.1 R Markdown

```r
# R Markdown基本结构
# ---
# title: "报告标题"
# author: "作者"
# date: "`r Sys.Date()`"
# output:
#   html_document:
#     toc: true
#     toc_float: true
#   pdf_document:
#     toc: true
# ---
# 
# # 一级标题
# 
# 这是正文内容。
# 
# ```{r chunk-name, echo=FALSE, warning=FALSE, message=FALSE}
# # R代码块
# library(ggplot2)
# ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point()
# ```

# 参数化报告
# ---
# title: "参数化报告"
# output: html_document
# params:
#   dataset: "mtcars"
#   variable: "mpg"
# ---
# 
# ```{r}
# data <- get(params$dataset)
# ggplot(data, aes(x = !!sym(params$variable))) + geom_histogram()
# ```

# 使用knitr动态生成内容
library(knitr)
kable(mtcars[1:5, ], caption = "mtcars数据集前5行")

# 在代码中生成R Markdown
library(rmarkdown)
temp_report <- tempfile(fileext = ".Rmd")
writeLines(c(
  "---",
  "title: '动态报告'",
  "output: html_document",
  "---",
  "",
  "```{r}",
  "library(ggplot2)",
  "ggplot(mtcars, aes(x = wt, y = mpg)) + geom_point()",
  "```"
), temp_report)
render(temp_report, output_file = "dynamic_report.html")
```

### 6.2 Shiny交互式应用

```r
# 基本Shiny应用结构
library(shiny)
library(ggplot2)

ui <- fluidPage(
  titlePanel("汽车数据分析"),
  sidebarLayout(
    sidebarPanel(
      selectInput("variable", "选择变量:",
                  choices = names(mtcars)[-1]),
      sliderInput("bins", "直方图分组数:",
                  min = 5, max = 30, value = 15)
    ),
    mainPanel(
      plotOutput("distPlot"),
      verbatimTextOutput("summary")
    )
  )
)

server <- function(input, output) {
  output$distPlot <- renderPlot({
    ggplot(mtcars, aes(x = !!sym(input$variable))) +
      geom_histogram(bins = input$bins, fill = "steelblue") +
      labs(title = paste(input$variable, "的分布"))
  })
  
  output$summary <- renderPrint({
    summary(mtcars[[input$variable]])
  })
}

shinyApp(ui = ui, server = server)

# 高级Shiny功能
# 响应式表达式
server <- function(input, output, session) {
  # 响应式数据
  filtered_data <- reactive({
    mtcars[mtcars$cyl == input$cyl_select, ]
  })
  
  # 观察者
  observe({
    updateSelectInput(session, "gear_select",
                      choices = unique(filtered_data()$gear))
  })
  
  # 事件观察者
  observeEvent(input$reset, {
    updateSelectInput(session, "cyl_select", selected = 4)
  })
  
  # 输出
  output$table <- renderDataTable({
    filtered_data()
  })
}

# Shiny模块
plotModuleUI <- function(id) {
  ns <- NS(id)
  tagList(
    plotOutput(ns("plot")),
    sliderInput(ns("bins"), "分组数", 5, 30, 15)
  )
}

plotModule <- function(input, output, session, data) {
  output$plot <- renderPlot({
    ggplot(data(), aes(x = mpg)) +
      geom_histogram(bins = input$bins)
  })
}
```

### 6.3 Flexdashboard

```r
# Flexdashboard示例
# ---
# title: "汽车数据分析仪表板"
# output: 
#   flexdashboard::flex_dashboard:
#     orientation: columns
#     vertical_layout: fill
#     theme: cosmo
# ---
# 
# ```{r setup, include=FALSE}
# library(flexdashboard)
# library(ggplot2)
# library(DT)
# ```
# 
# 列 {.sidebar}
# ---------------------------------------------------------
# 
# ### 过滤器
# 
# ```{r}
# selectInput("cyl", "气缸数:", 
#             choices = c("所有" = "all", "4缸" = "4", 
#                        "6缸" = "6", "8缸" = "8"),
#             selected = "all")
# 
# sliderInput("mpg_range", "油耗范围:",
#             min = min(mtcars$mpg),
#             max = max(mtcars$mpg),
#             value = c(min(mtcars$mpg), max(mtcars$mpg)))
# ```
# 
# 列
# ---------------------------------------------------------
# 
# ### 油耗分布
# 
# ```{r}
# renderPlot({
#   data <- mtcars
#   if (input$cyl != "all") {
#     data <- data[data$cyl == as.numeric(input$cyl), ]
#   }
#   data <- data[data$mpg >= input$mpg_range[1] & 
#                data$mpg <= input$mpg_range[2], ]
#   
#   ggplot(data, aes(x = mpg)) +
#     geom_histogram(bins = 20, fill = "steelblue") +
#     labs(title = "油耗分布", x = "油耗", y = "频数")
# })
# ```
# 
# ### 数据表
# 
# ```{r}
# renderDataTable({
#   data <- mtcars
#   if (input$cyl != "all") {
#     data <- data[data$cyl == as.numeric(input$cyl), ]
#   }
#   data <- data[data$mpg >= input$mpg_range[1] & 
#                data$mpg <= input$mpg_range[2], ]
#   datatable(data, options = list(pageLength = 5))
# })
# ```
```

## 七、工作流与项目管理

### 7.1 项目结构

```r
# 推荐的项目结构
# my_project/
# ├── data/
# │   ├── raw/          # 原始数据（不可修改）
# │   ├── processed/    # 处理后的数据
# │   └── external/     # 外部数据
# ├── docs/             # 文档
# ├── figs/             # 生成的图形
# ├── output/           # 输出结果
# ├── R/                # R源代码
# │   ├── 01_data_preprocessing.R
# │   ├── 02_analysis.R
# │   └── 03_visualization.R
# ├── tests/            # 测试代码
# ├── .gitignore        # Git忽略文件
# ├── .Rprofile         # R配置文件
# ├── DESCRIPTION       # 项目描述（如创建R包）
# ├── LICENSE           # 许可证
# ├── Makefile          # 构建脚本
# ├── README.md         # 项目说明
# └── my_project.Rproj  # RStudio项目文件

# 使用here包管理路径
library(here)
data_path <- here("data", "raw", "dataset.csv")
output_path <- here("output", "results.rds")

# 创建项目模板
library(usethis)
create_package("my_package")  # 创建R包
create_project("my_analysis")  # 创建分析项目
use_readme_md()  # 创建README
use_mit_license()  # 添加MIT许可证
use_testthat()  # 设置测试框架
use_git()  # 初始化Git仓库
```

### 7.2 版本控制

```r
# 使用git2r进行版本控制
library(git2r)

# 初始化仓库
repo <- init("my_project")

# 添加文件
add(repo, "*.R")
add(repo, "data/*.csv")

# 提交更改
commit(repo, message = "初始提交")

# 查看状态
status(repo)

# 查看历史
commits(repo)

# 使用gert简化Git操作
library(gert)
git_init("my_project")
git_add("*.R")
git_commit("添加R脚本")
git_log()

# 配置Git
git_config_global_set("user.name", "Your Name")
git_config_global_set("user.email", "your.email@example.com")
```

### 7.3 测试与验证

```r
# 使用testthat进行单元测试
library(testthat)

# 测试文件示例：test_calculations.R
test_that("加法函数工作正常", {
  expect_equal(add(2, 3), 5)
  expect_equal(add(-1, 1), 0)
  expect_error(add("a", 1))
})

test_that("数据预处理函数", {
  data <- data.frame(x = c(1, 2, NA, 4), y = c("a", "b", "c", "d"))
  result <- clean_data(data)
  expect_equal(nrow(result), 3)  # 移除NA行
  expect_false(any(is.na(result$x)))
})

# 运行测试
test_dir("tests/")

# 使用covr进行代码覆盖率测试
library(covr)
cov <- package_coverage()
report(cov)

# 使用lintr进行代码风格检查
library(lintr)
lint("R/my_function.R")
lint_package()  # 检查整个包

# 使用goodpractice检查代码质量
library(goodpractice)
gp <- goodpractice("path/to/package")
results(gp)
```

### 7.4 文档生成

```r
# 使用roxygen2生成文档
#' 计算两个数的和
#'
#' 这个函数计算两个数值型向量的和。
#'
#' @param x 第一个数值向量
#' @param y 第二个数值向量
#' @return x和y的和
#' @examples
#' add(2, 3)  # 返回5
#' add(c(1, 2), c(3, 4))  # 返回c(4, 6)
#' @export
add <- function(x, y) {
  x + y
}

# 生成文档
library(roxygen2)
roxygen2::roxygenise()

# 使用pkgdown生成网站文档
library(pkgdown)
build_site()

# 使用bookdown编写书籍
library(bookdown)
render_book("index.Rmd", output_format = "bookdown::gitbook")

# 使用blogdown创建博客
library(blogdown)
new_site()  # 创建新网站
build_site()  # 构建网站
serve_site()  # 本地预览
```

## 八、特殊主题

### 8.1 生物信息学分析

```r
# Bioconductor生物信息学分析
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

# 安装Bioconductor包
BiocManager::install("DESeq2")
BiocManager::install("limma")
BiocManager::install("edgeR")

# RNA-seq差异表达分析
library(DESeq2)

# 创建DESeqDataSet
dds <- DESeqDataSetFromMatrix(countData = counts,
                              colData = colData,
                              design = ~ condition)

# 差异表达分析
dds <- DESeq(dds)
results <- results(dds)

# 结果可视化
plotMA(results, main = "MA图")

# 使用limma进行微阵列数据分析
library(limma)
design <- model.matrix(~ 0 + factor(group))
fit <- lmFit(expressionData, design)
fit <- eBayes(fit)
topTable(fit, coef = 2, number = 10)
```

### 8.2 空间数据分析

```r
# 空间数据分析
library(sf)        # 简单要素
library(sp)        # 空间数据
library(raster)    # 栅格数据
library(leaflet)   # 交互式地图

# 读取空间数据
shapefile <- st_read("path/to/shapefile.shp")
raster_data <- raster("path/to/raster.tif")

# 空间操作
intersection <- st_intersection(shapefile1, shapefile2)
buffer <- st_buffer(shapefile, dist = 1000)  # 1000米缓冲区

# 空间统计
library(spdep)
# 创建空间权重矩阵
nb <- poly2nb(shapefile)
listw <- nb2listw(nb)

# 莫兰检验（空间自相关）
moran.test(shapefile$variable, listw)

# 空间回归
library(spatialreg)
sar_model <- lagsarlm(variable ~ predictors, data = shapefile, listw = listw)
summary(sar_model)
```

### 8.3 网络分析

```r
# 网络分析
library(igraph)
library(visNetwork)
library(tidygraph)
library(ggraph)

# 创建网络
edges <- data.frame(from = c(1, 1, 2, 2, 3, 3),
                    to = c(2, 3, 3, 4, 4, 5),
                    weight = c(1, 2, 3, 1, 2, 1))
nodes <- data.frame(id = 1:5, label = c("A", "B", "C", "D", "E"))

g <- graph_from_data_frame(edges, vertices = nodes, directed = FALSE)

# 网络指标
degree(g)  # 度中心性
betweenness(g)  # 中介中心性
closeness(g)  # 接近中心性
eigen_centrality(g)$vector  # 特征向量中心性

# 社区检测
community <- cluster_louvain(g)
membership(community)

# 可视化
plot(g, vertex.size = 20, vertex.color = "lightblue")

# 交互式可视化
visNetwork(nodes, edges) %>%
  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE)

# 使用ggraph进行高级可视化
ggraph(g, layout = "fr") +
  geom_edge_link(aes(width = weight), alpha = 0.8) +
  geom_node_point(aes(size = degree(g)), color = "lightblue") +
  geom_node_text(aes(label = label), repel = TRUE) +
  theme_graph()
```

### 8.4 文本挖掘

```r
# 文本挖掘
library(tm)          # 文本挖掘
library(tidytext)    # 文本处理
library(wordcloud)   # 词云
library(topicmodels) # 主题模型

# 创建语料库
docs <- c("这是第一个文档。", "这是第二个文档，包含更多内容。",
          "第三个文档与自然语言处理相关。")
corpus <- Corpus(VectorSource(docs))

# 文本预处理
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("chinese"))
corpus <- tm_map(corpus, stripWhitespace)

# 创建文档-词项矩阵
dtm <- DocumentTermMatrix(corpus)
inspect(dtm)

# 词频分析
freq <- colSums(as.matrix(dtm))
wordcloud(names(freq), freq, max.words = 50, 
          colors = brewer.pal(8, "Dark2"))

# 情感分析
library(syuzhet)
sentiment <- get_nrc_sentiment(docs)
sentiment_scores <- data.frame(
  document = 1:length(docs),
  sentiment = sentiment
)

# 主题模型（LDA）
lda_model <- LDA(dtm, k = 2, control = list(seed = 1234))
topics <- topics(lda_model, 1)
terms <- terms(lda_model, 5)  # 每个主题的前5个词
```

## 总结

这份补充内容涵盖了原笔记中缺少的多个重要领域：

1. **统计建模与机器学习**：线性模型、混合效应模型、时间序列、机器学习算法
2. **数据输入输出**：多种文件格式、数据库连接、Web数据抓取
3. **高级可视化**：基础绘图系统、lattice、交互式可视化
4. **高性能计算**：并行计算、大数据处理、Rcpp
5. **调试与优化**：调试工具、性能分析、代码优化
6. **报告与应用**：R Markdown、Shiny、Flexdashboard
7. **工作流管理**：项目结构、版本控制、测试、文档
8. **特殊应用**：生物信息学、空间数据、网络分析、文本挖掘

这些内容将使R语言知识体系更加完整，覆盖从基础到高级，从数据分析到应用开发的各个方面。